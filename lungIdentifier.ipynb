{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kütüphanelerin Yüklenmesi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from metods import *\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genel Değişkenlerin Belirlenmesi\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "models_folder = \"models\\\\\" #model klasörü oluşturuluyor\n",
    "\n",
    "modelName = models_folder + \"LungIdentifierModelVGG16Testing2.h5\" #Model ismi\n",
    "\n",
    "#Dosya yolları\n",
    "healty_path = \"C:\\\\Users\\\\ugur_\\\\Python Projects\\\\LungClassifier\\\\NIH Data\\\\Healty\\\\\"\n",
    "healty_mask_path = \"C:\\\\Users\\\\ugur_\\\\Python Projects\\\\LungClassifier\\\\NIH Data\\\\Healty Mask\\\\\"\n",
    "healty_segmented_path = \"C:\\\\Users\\\\ugur_\\\\Python Projects\\\\LungClassifier\\\\NIH Data\\\\Healty Segmented\\\\\"\n",
    "\n",
    "pneu_path = \"C:\\\\Users\\\\ugur_\\\\Python Projects\\\\LungClassifier\\\\NIH Data\\\\Pneumothorax\\\\\"\n",
    "pneu_mask_path = \"C:\\\\Users\\\\ugur_\\\\Python Projects\\\\LungClassifier\\\\NIH Data\\\\Pneumothorax Mask\\\\\"\n",
    "pneu_segmented_path = \"C:\\\\Users\\\\ugur_\\\\Python Projects\\\\LungClassifier\\\\NIH Data\\\\Pneumothorax Segmented\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40768, 128, 128, 3)\n",
      "(40768, 2)\n"
     ]
    }
   ],
   "source": [
    "#Veri seti yüklenme aşaması\n",
    "\n",
    "#Eğitim verisi için dosya isimlerini klasörlerden listeye aktarıyoruz.\n",
    "healty_segmented_images = os.listdir(healty_segmented_path)\n",
    "pneu_segmented_images = os.listdir(pneu_segmented_path)\n",
    "\n",
    "#Veriyi daha hızlı yazabilmek için ön tanımlı X ve Y değişkenlerimizi oluşturuyoruz.\n",
    "X_train = np.zeros((len(healty_segmented_images) + len(pneu_segmented_images), IMG_HEIGHT, IMG_WIDTH), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(healty_segmented_images) + len(pneu_segmented_images)), dtype=np.bool)\n",
    "\n",
    "\n",
    "#Sağlıklı akciğer segmentlerini yüklüyoruz.\n",
    "for i, img_id in enumerate(healty_segmented_images):\n",
    "    file_name = healty_segmented_path + img_id\n",
    "\n",
    "    img = readImages(file_name, is_gray=0)\n",
    "    \n",
    "    X_train[i] = img\n",
    "    Y_train[i] = 0\n",
    "\n",
    "#Sağlıklı veri miktarımız az olduğu için aynalama taktiği ile sağlıklı verilerimizi iki katına çıkarıyoruz.\n",
    "X_train2 = np.flip(X_train, axis=2)\n",
    "X_train = np.append(X_train, X_train2, axis=0)\n",
    "Y_train = np.append(Y_train, Y_train, axis=0)\n",
    "\n",
    "#Pnömotoraks akciğer segmentlerini yüklüyoruz.\n",
    "for i, img_id in enumerate(pneu_segmented_images):\n",
    "    file_name = pneu_segmented_path + img_id\n",
    "    \n",
    "    img = readImages(file_name, is_gray=0)\n",
    "    \n",
    "    X_train[len(healty_segmented_images) + i] = img\n",
    "    Y_train[len(healty_segmented_images) + i] = 1\n",
    "\n",
    "#X_train verimizi VGG16 modelimiz için uygun hale getiriyoruz. (3 Kanallı ve 4 boyutlu hale getiriyoruz)\n",
    "X_train = np.repeat(X_train[..., np.newaxis], 3, -1)\n",
    "X_train = X_train.reshape(-1, 128, 128, 3)\n",
    "\n",
    "#Kategorik eğitim yapacağımız için Y verilerimizi kategorik veriye çeviriyoruz.\n",
    "Y_train = to_categorical(Y_train)\n",
    "\n",
    "#Veri yükleme işleminden sonra işe yaramayan ve bellekte boş veri kaplamamasını istediğimiz değişkenleri hafızadan siliyoruz.\n",
    "X_train2 = None\n",
    "healty_segmented_images = None\n",
    "pneu_segmented_images = None\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:  (32614, 128, 128, 3)\n",
      "Test Data:  (8154, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "#Verimizi eğitim ve test olmak üzere 2 parçaya bölüyoruz.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=8)\n",
    "\n",
    "print(\"Train Data: \", X_train.shape)\n",
    "print(\"Test Data: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 16386     \n",
      "=================================================================\n",
      "Total params: 14,731,074\n",
      "Trainable params: 16,386\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "#VGG16 Modelimizin giriş katmanını oluşturuyoruz.\n",
    "input_layer=layers.Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "\n",
    "#VGG16 Modelimizi ImageNet ağırlıkları ile yüklüyoruz.\n",
    "model_VGG16=VGG16(weights='imagenet', input_tensor=input_layer, include_top=False)\n",
    "\n",
    "#VGG16 Modelinin çıkış katmanını alıyoruz.\n",
    "last_layer=model_VGG16.output \n",
    "\n",
    "#2 sınıftan oluşan özel çıkış katmanımızı oluşturuyoruz.\n",
    "flatten=layers.Flatten()(last_layer) \n",
    "output_layer=layers.Dense(2, activation='softmax')(flatten)\n",
    "\n",
    "model=models.Model(inputs=input_layer, outputs=output_layer)\n",
    "#Yeni bir model oluşturup giriş ve çıkış katmanlarını kendi katmanlarımız ile değiştiriyoruz.\n",
    "\n",
    "#Çıkış katmanı haricindeki tüm katmanların eğitimini kapatıyoruz.\n",
    "for layer in model.layers[:-1]:\n",
    "    layer.trainable=False\n",
    "\n",
    "model_EfficientNetB7 = None\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "5436/5436 [==============================] - 76s 12ms/step - loss: 0.2090 - accuracy: 0.9194 - val_loss: 0.1709 - val_accuracy: 0.9431\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.94310, saving model to models\\LungIdentifierModelVGG16Testing2.h5\n",
      "Epoch 2/40\n",
      "5436/5436 [==============================] - 53s 10ms/step - loss: 0.1599 - accuracy: 0.9417 - val_loss: 0.1884 - val_accuracy: 0.9451\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.94310 to 0.94506, saving model to models\\LungIdentifierModelVGG16Testing2.h5\n",
      "Epoch 3/40\n",
      "5434/5436 [============================>.] - ETA: 0s - loss: 0.1480 - accuracy: 0.9483"
     ]
    }
   ],
   "source": [
    "#Modelimizi derleyip checkpointlerini belirliyoruz.\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "earlystopper = EarlyStopping(patience=25, verbose=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "checkpoint = ModelCheckpoint(modelName, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint, learning_rate_reduction, earlystopper]\n",
    "\n",
    "#Eğitimi başlatıyoruz.\n",
    "history = model.fit(X_train/255.0, Y_train, validation_data=(X_test/255.0, Y_test), batch_size=6, epochs=40, callbacks=callbacks_list, shuffle=True)\n",
    "\n",
    "#Eğitim sonuçlarını grafiğe döküyoruz.\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training ve Validation loss oranı')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.title('Training ve Validation Accuracy oranı')\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8186,)\n"
     ]
    }
   ],
   "source": [
    "#Test veri sonuçlarını pandas ile dataframe haline getiriyoruz.\n",
    "df_test = pd.DataFrame()\n",
    "Y_test_normal = np.argmax(Y_test, axis=-1)\n",
    "\n",
    "print(Y_test_normal.shape)\n",
    "\n",
    "df_test['type'] = Y_test_normal\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doğruluk oranı %96.01759100903982\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  preds\n",
       "0     0      0\n",
       "1     0      0\n",
       "2     0      0\n",
       "3     1      1\n",
       "4     0      0\n",
       "5     0      0\n",
       "6     1      1\n",
       "7     1      1\n",
       "8     1      1\n",
       "9     1      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#En iyi modeli yükleyerek tahmin işlemini gerçekleştiriyoruz.\n",
    "model = load_model(modelName)\n",
    "preds = np.argmax(model.predict(X_test/255.0), axis=-1)\n",
    "\n",
    "#Tahmin sonuçlarını gerçek sonuçlar ile karşılaştırıyoruz.\n",
    "df_test['preds'] = np.round(preds)\n",
    "df_test['preds'] = df_test['preds'].apply(np.int)\n",
    "\n",
    "wrongs_df = df_test.loc[df_test['type'] != df_test['preds']]\n",
    "\n",
    "print(f\"Doğruluk oranı %{100 - (len(wrongs_df) * 100 / len(df_test))}\")\n",
    "\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9601759100903983\n",
      "Sensitivity :  0.9737903225806451\n",
      "Specificity :  0.932967032967033\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "#Modelimizin metriklerini hesaplıyoruz.\n",
    "cm1 = confusion_matrix(df_test[['type']], df_test['preds'])\n",
    "sn.heatmap(cm1, annot=True, annot_kws={\"size\": 16}, fmt=\"d\")\n",
    "\n",
    "total1=sum(sum(cm1))\n",
    "\n",
    "accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print('Specificity : ', specificity1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8ca9f36e1327da540f9f8b65b3b6fee14f84eb0ea34b0227d72885446c195df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
