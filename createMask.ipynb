{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras_unet.models import custom_unet\n",
    "from skimage.io import imread\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showRandomPredict(images, masks, predicts, sample_count, if_predicted= False):\n",
    "    sample_count = sample_count * 4\n",
    "    plt.figure(figsize=(15, 30))\n",
    "    for i in range(0, sample_count, 4):\n",
    "        img_index = random.choice(range(len(images)))\n",
    "        plt.subplot(5,4,i + 1)\n",
    "        random_img = images[img_index,:,:]\n",
    "        random_img = cv2.resize(random_img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "        plt.imshow(random_img, cmap=plt.cm.bone)\n",
    "        plt.axis('off')\n",
    "        plt.title('Lung X-Ray')\n",
    "\n",
    "        plt.subplot(5,4,i + 2)\n",
    "        random_mask = masks[img_index,:,:]\n",
    "        random_mask = cv2.resize(random_mask, (IMG_HEIGHT, IMG_WIDTH))\n",
    "        plt.imshow(random_mask, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title('Mask Ground Truth')\n",
    "        \n",
    "        if not if_predicted:\n",
    "            continue\n",
    "        random_pred = predicts[img_index,:,:,0]\n",
    "        plt.subplot(5,4,i + 3)\n",
    "        plt.imshow(random_pred, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title('Predicted Mask')\n",
    "\n",
    "        plt.subplot(5,4,i + 4)\n",
    "        plt.imshow(cv2.bitwise_and(images[img_index,:,:], images[img_index,:,:], mask=random_pred.astype(np.uint8)), cmap=plt.cm.bone)\n",
    "        plt.axis('off')\n",
    "        plt.title('Predicted Lung Segmentation')\n",
    "    plt.show()\n",
    "\n",
    "def SaveGeneratedMask(Image_collection_path, save_path, modelName):\n",
    "    \n",
    "    test_images = os.listdir(Image_collection_path)\n",
    "    x = np.zeros((len(test_images), IMG_HEIGHT, IMG_WIDTH))\n",
    "    \n",
    "    for i, img_id in enumerate(test_images):\n",
    "        img_collection = Image_collection_path  + img_id\n",
    "\n",
    "        cv2_image = cv2.imread(img_collection,0)\n",
    "        cv2_image = cv2.resize(cv2_image, (IMG_HEIGHT, IMG_WIDTH))\n",
    "        cv2.imwrite('img.jpg', cv2_image)\n",
    "        img = imread('img.jpg')\n",
    "        x[i] = img\n",
    "        os.remove('img.jpg')\n",
    "    \n",
    "    model2 = load_model(modelName)\n",
    "    pred_img = model2.predict(x/255.)*255.0\n",
    "    \n",
    "    for j, img_id in enumerate(test_images):   \n",
    "        new_img_path =save_path + 'mask_' + img_id\n",
    "        cv2.imwrite(new_img_path, pred_img[j])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 704\n"
     ]
    }
   ],
   "source": [
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "\n",
    "image_path = \"C:\\\\Users\\\\ugur_\\\\Python Projects\\\\DATA\\\\Lung Segmentation\\\\CXR_png\\\\\"\n",
    "mask_path = \"C:\\\\Users\\\\ugur_\\\\Python Projects\\\\DATA\\Lung Segmentation\\\\masks\\\\\"\n",
    "\n",
    "images = os.listdir(image_path)\n",
    "mask = os.listdir(mask_path)\n",
    "\n",
    "print(len(images), len(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2 = [fName.split(\".png\")[0] for fName in mask]\n",
    "image_file_name = [fName.split(\"_mask\")[0] for fName in mask2]\n",
    "print(len(image_file_name), len(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = [i for i in mask if \"mask\" in i]\n",
    "print(len(check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(mask), IMG_HEIGHT, IMG_WIDTH))\n",
    "y = np.zeros((len(mask), IMG_HEIGHT, IMG_WIDTH))\n",
    "\n",
    "for i, img_id in enumerate(image_file_name):\n",
    "    \n",
    "    file_path = image_path  + img_id + \".png\"\n",
    "    \n",
    "    # read the file as an array\n",
    "    cv2_image = cv2.imread(file_path, 0)\n",
    "    # resize the image\n",
    "    cv2_image = cv2.resize(cv2_image, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    # save the image at the destination as a jpg file\n",
    "    cv2.imwrite('img.jpg', cv2_image)\n",
    "    \n",
    "    # read the image using skimage\n",
    "    img = imread('img.jpg')\n",
    "    x[i] = img\n",
    "    \n",
    "    os.remove('img.jpg')\n",
    "\n",
    "    \n",
    "for i, img_id in enumerate(mask):\n",
    "    \n",
    "    file_path = mask_path  + img_id \n",
    "    \n",
    "    # read the file as an array\n",
    "    cv2_image = cv2.imread(file_path, 0)\n",
    "    # resize the image\n",
    "    cv2_image = cv2.resize(cv2_image, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    # save the image at the destination as a jpg file\n",
    "    cv2.imwrite('img.jpg', cv2_image)\n",
    "    \n",
    "    # read the image using skimage\n",
    "    img = imread('img.jpg')\n",
    "    y[i] = img\n",
    "    \n",
    "    os.remove('img.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_m, y_test_m = train_test_split(x, y, test_size=0.2, random_state=123)\n",
    "\n",
    "x2 = np.flip(X_train , axis = 2)\n",
    "y2 = np.flip(y_train_m , axis = 2)\n",
    "\n",
    "X_train= np.append(X_train, x2,axis=0)\n",
    "y_train_m = np.append(y_train_m, y2,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape,y_train_m.shape)\n",
    "showRandomPredict(X_train, y_train_m, y_train_m, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_unet(\n",
    "    (128, 128, 1),\n",
    "    use_batch_norm=True,\n",
    "    num_classes=1,\n",
    "    filters=64,\n",
    "    dropout=0.2,\n",
    "    output_activation='sigmoid',)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_accuracy', patience=4, verbose=1, min_delta=1e-4),\n",
    "    ModelCheckpoint('model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'),]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_m2 = (y_test_m/255.> .5).astype(int)\n",
    "y_train_m2 = (y_train_m/255.> .5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.fit(\n",
    "    X_train/255., y_train_m2,   \n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_test/255., y_test_m2),\n",
    "    epochs=15, batch_size=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model.h5\")\n",
    "\n",
    "plt.plot(h.history['accuracy'])\n",
    "plt.plot(h.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(h.history['loss'])\n",
    "plt.plot(h.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "losses = h.history['loss']\n",
    "accs = h.history['accuracy']\n",
    "val_losses = h.history['val_loss']\n",
    "val_accs = h.history['val_accuracy']\n",
    "epochs = len(losses)\n",
    "\n",
    "preds = model.predict(X_test/255.)*255\n",
    "showRandomPredict(X_test, y_test_m, preds, 2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='loss', patience=3, verbose=1, factor=0.5, min_lr=0.00001),\n",
    "    ModelCheckpoint('model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = model.fit(\n",
    "    X_train/255., y_train_m2,\n",
    "    validation_data=(X_test/255., y_test_m2),\n",
    "    epochs=50, batch_size=16,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model.h5')\n",
    "\n",
    "plt.plot(h2.history['accuracy'])\n",
    "plt.plot(h2.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(h2.history['loss'])\n",
    "plt.plot(h2.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "losses = h2.history['loss']\n",
    "accs = h2.history['accuracy']\n",
    "val_losses = h2.history['val_loss']\n",
    "val_accs = h2.history['val_accuracy']\n",
    "epochs = len(losses)\n",
    "showRandomPredict(X_test, y_test_m, preds, 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_collection_path = 'C:\\\\Users\\\\ugur_\\\\Python Projects\\\\LungClassifier\\\\images\\\\images_001\\\\images\\\\'\n",
    "save_path ='C:\\\\Users\\\\ugur_\\\\Python Projects\\\\LungClassifier\\\\Predicted Mask\\\\'\n",
    "SaveGeneratedMask(Image_collection_path=Image_collection_path, save_path= save_path, modelName='model.h5')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8ca9f36e1327da540f9f8b65b3b6fee14f84eb0ea34b0227d72885446c195df"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
